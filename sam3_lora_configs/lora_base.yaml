# @package _global_
# LoRA Fine-tuning Configuration for SAM3
# Extends the official SAM3 training configs
# AI Research Group - KMUTT

defaults:
  - _self_

# ============================================================================
# Paths Configuration (Change this to your own paths)
# ============================================================================
paths:
  dataset_root: <YOUR_DATASET_DIR>  # Directory containing COCO format data
  experiment_log_dir: <YOUR_EXPERIMENT_LOG_DIR>
  bpe_path: sam3/assets/bpe_simple_vocab_16e6.txt.gz

# ============================================================================
# LoRA Configuration
# ============================================================================
lora:
  rank: 8                      # LoRA rank (4, 8, 16, 32)
  alpha: 16                    # Scaling factor (typically 2x rank)
  dropout: 0.0                 # Dropout for LoRA layers

  # Target modules - which linear layers to apply LoRA to
  target_modules:
    - "q_proj"                 # Query projection
    - "k_proj"                 # Key projection
    - "v_proj"                 # Value projection
    - "out_proj"               # Output projection

  # Component-level control
  apply_to_vision_encoder: true    # Vision backbone (ViT)
  apply_to_text_encoder: true      # Text encoder
  apply_to_detr_encoder: true      # DETR encoder
  apply_to_detr_decoder: true      # DETR decoder

# ============================================================================
# Training Configuration
# ============================================================================
training:
  # Dataset paths (COCO format)
  img_folder_train: ${paths.dataset_root}/train/
  ann_file_train: ${paths.dataset_root}/train/_annotations.coco.json
  img_folder_val: ${paths.dataset_root}/valid/
  ann_file_val: ${paths.dataset_root}/valid/_annotations.coco.json

  # Enable segmentation masks (set to true if you have segmentation annotations)
  enable_segmentation: true

  # Training parameters
  max_epochs: 20
  batch_size: 1                    # Per-GPU batch size
  gradient_accumulation_steps: 4   # Effective batch size = batch_size * gradient_accumulation_steps
  num_train_workers: 10
  num_val_workers: 2

  # Learning rates
  lr_scale: 0.1                    # Global LR scale factor
  lr_transformer: 8e-5             # Transformer LR (scaled by lr_scale)
  lr_vision_backbone: 2.5e-5       # Vision backbone LR
  lr_language_backbone: 5e-6       # Text encoder LR

  # Optimization
  weight_decay: 0.1
  gradient_clip_max_norm: 0.1
  layer_decay_vision: 0.9

  # Scheduler
  scheduler_timescale: 20
  scheduler_warmup: 20
  scheduler_cooldown: 20

  # Mixed precision
  amp_enabled: true
  amp_dtype: bfloat16              # or float16

  # Validation
  val_epoch_freq: 5                # Validate every N epochs
  skip_first_val: true

  # Checkpointing
  save_checkpoints: true
  checkpoint_freq: 5               # Save every N epochs

# ============================================================================
# Scratch Configuration (shared parameters)
# ============================================================================
scratch:
  # Model parameters
  resolution: 1008
  d_model: 256
  max_ann_per_img: 200

  # Normalization
  train_norm_mean: [0.5, 0.5, 0.5]
  train_norm_std: [0.5, 0.5, 0.5]

  # Matcher
  matcher:
    _target_: sam3.train.matcher.BinaryHungarianMatcherV2
    focal: true
    cost_class: 2.0
    cost_bbox: 5.0
    cost_giou: 2.0
    alpha: 0.25
    gamma: 2
    stable: false

  # Position embedding
  pos_embed:
    _target_: sam3.model.position_encoding.PositionEmbeddingSine
    num_pos_feats: ${scratch.d_model}
    normalize: true
    scale: null
    temperature: 10000

# ============================================================================
# Loss Configuration
# ============================================================================
loss:
  _target_: sam3.train.loss.sam3_loss.Sam3LossWrapper
  matcher: ${scratch.matcher}
  o2m_weight: 2.0
  o2m_matcher:
    _target_: sam3.train.matcher.BinaryOneToManyMatcher
    alpha: 0.3
    threshold: 0.4
    topk: 4
  use_o2m_matcher_on_o2m_aux: false

  # Loss functions for detection
  loss_fns_find:
    - _target_: sam3.train.loss.loss_fns.Boxes
      weight_dict:
        loss_bbox: 5.0
        loss_giou: 2.0

    - _target_: sam3.train.loss.loss_fns.IABCEMdetr
      weak_loss: false
      weight_dict:
        loss_ce: 20.0
        presence_loss: 20.0
      pos_weight: 10.0
      alpha: 0.25
      gamma: 2
      use_presence: true
      pos_focal: false
      pad_n_queries: 200
      pad_scale_pos: 1.0

    # Mask loss (enabled if training.enable_segmentation is true)
    - _target_: sam3.train.loss.loss_fns.Masks
      focal_alpha: 0.25
      focal_gamma: 2.0
      weight_dict:
        loss_mask: 200.0
        loss_dice: 10.0
      compute_aux: false

  # Semantic segmentation loss (optional)
  loss_fn_semantic_seg: null

  scale_by_find_batch_size: true

# ============================================================================
# Data Transforms
# ============================================================================
train_transforms:
  - _target_: sam3.train.transforms.basic_for_api.ComposeAPI
    transforms:
      - _target_: sam3.train.transforms.filter_query_transforms.FlexibleFilterFindGetQueries
        query_filter:
          _target_: sam3.train.transforms.filter_query_transforms.FilterCrowds

      - _target_: sam3.train.transforms.point_sampling.RandomizeInputBbox
        box_noise_std: 0.1
        box_noise_max: 20

      - _target_: sam3.train.transforms.segmentation.DecodeRle

      - _target_: sam3.train.transforms.basic_for_api.RandomResizeAPI
        sizes:
          _target_: sam3.train.transforms.basic.get_random_resize_scales
          size: ${scratch.resolution}
          min_size: 480
          rounded: false
        max_size:
          _target_: sam3.train.transforms.basic.get_random_resize_max_size
          size: ${scratch.resolution}
        square: true
        consistent_transform: false

      - _target_: sam3.train.transforms.basic_for_api.PadToSizeAPI
        size: ${scratch.resolution}
        consistent_transform: false

      - _target_: sam3.train.transforms.basic_for_api.ToTensorAPI

      - _target_: sam3.train.transforms.filter_query_transforms.FlexibleFilterFindGetQueries
        query_filter:
          _target_: sam3.train.transforms.filter_query_transforms.FilterEmptyTargets

      - _target_: sam3.train.transforms.basic_for_api.NormalizeAPI
        mean: ${scratch.train_norm_mean}
        std: ${scratch.train_norm_std}

val_transforms:
  - _target_: sam3.train.transforms.basic_for_api.ComposeAPI
    transforms:
      - _target_: sam3.train.transforms.basic_for_api.RandomResizeAPI
        sizes: ${scratch.resolution}
        max_size:
          _target_: sam3.train.transforms.basic.get_random_resize_max_size
          size: ${scratch.resolution}
        square: true
        consistent_transform: false

      - _target_: sam3.train.transforms.basic_for_api.ToTensorAPI

      - _target_: sam3.train.transforms.basic_for_api.NormalizeAPI
        mean: ${scratch.train_norm_mean}
        std: ${scratch.train_norm_std}

# ============================================================================
# Trainer Configuration
# ============================================================================
trainer:
  _target_: sam3.train.trainer.Trainer

  max_epochs: ${training.max_epochs}
  accelerator: cuda
  seed_value: 42
  mode: train

  val_epoch_freq: ${training.val_epoch_freq}
  skip_first_val: ${training.skip_first_val}
  skip_saving_ckpts: false
  empty_gpu_mem_cache_after_eval: true

  gradient_accumulation_steps: ${training.gradient_accumulation_steps}

  # Distributed training
  distributed:
    backend: nccl
    find_unused_parameters: true
    gradient_as_bucket_view: true

  # Loss
  loss:
    all: ${loss}
    default:
      _target_: sam3.train.loss.sam3_loss.DummyLoss

  # Data loaders
  data:
    train:
      _target_: sam3.train.data.torch_dataset.TorchDataset
      dataset:
        _target_: sam3.train.data.sam3_image_dataset.Sam3ImageDataset
        img_folder: ${training.img_folder_train}
        ann_file: ${training.ann_file_train}
        transforms: ${train_transforms}
        load_segmentation: ${training.enable_segmentation}
        max_ann_per_img: 500000
        training: true
        use_caching: false

      shuffle: true
      batch_size: ${training.batch_size}
      num_workers: ${training.num_train_workers}
      pin_memory: true
      drop_last: true
      collate_fn:
        _target_: sam3.train.data.collator.collate_fn_api
        _partial_: true
        repeats: 1
        dict_key: all
        with_seg_masks: ${training.enable_segmentation}

    val:
      _target_: sam3.train.data.torch_dataset.TorchDataset
      dataset:
        _target_: sam3.train.data.sam3_image_dataset.Sam3ImageDataset
        img_folder: ${training.img_folder_val}
        ann_file: ${training.ann_file_val}
        transforms: ${val_transforms}
        load_segmentation: ${training.enable_segmentation}
        max_ann_per_img: 100000
        training: false
        coco_json_loader:
          _target_: sam3.train.data.coco_json_loaders.COCO_FROM_JSON
          include_negatives: true
          category_chunk_size: 2
          _partial_: true

      shuffle: false
      batch_size: 1
      num_workers: ${training.num_val_workers}
      pin_memory: true
      drop_last: false
      collate_fn:
        _target_: sam3.train.data.collator.collate_fn_api
        _partial_: true
        repeats: 1
        dict_key: all
        with_seg_masks: ${training.enable_segmentation}

  # Model with LoRA
  model:
    _target_: sam3_lora_wrapper.wrap_sam3_model_with_lora
    model_builder_fn:
      _target_: sam3.model_builder.build_sam3_image_model
      bpe_path: ${paths.bpe_path}
      device: cpus
      eval_mode: false
      enable_segmentation: ${training.enable_segmentation}
    lora_config: ${lora}

  # Optimization
  optim:
    amp:
      enabled: ${training.amp_enabled}
      amp_dtype: ${training.amp_dtype}

    optimizer:
      _target_: torch.optim.AdamW

    gradient_clip:
      _target_: sam3.train.optim.optimizer.GradientClipper
      max_norm: ${training.gradient_clip_max_norm}
      norm_type: 2

    param_group_modifiers:
      - _target_: sam3.train.optim.optimizer.layer_decay_param_modifier
        _partial_: true
        layer_decay_value: ${training.layer_decay_vision}
        apply_to: 'backbone.vision_backbone.trunk'
        overrides:
          - pattern: '*pos_embed*'
            value: 1.0

    options:
      lr:
        - scheduler:
            _target_: sam3.train.optim.schedulers.InverseSquareRootParamScheduler
            base_lr: ${training.lr_transformer}
            timescale: ${training.scheduler_timescale}
            warmup_steps: ${training.scheduler_warmup}
            cooldown_steps: ${training.scheduler_cooldown}

        - scheduler:
            _target_: sam3.train.optim.schedulers.InverseSquareRootParamScheduler
            base_lr: ${training.lr_vision_backbone}
            timescale: ${training.scheduler_timescale}
            warmup_steps: ${training.scheduler_warmup}
            cooldown_steps: ${training.scheduler_cooldown}
          param_names:
            - 'backbone.vision_backbone.*'

        - scheduler:
            _target_: sam3.train.optim.schedulers.InverseSquareRootParamScheduler
            base_lr: ${training.lr_language_backbone}
            timescale: ${training.scheduler_timescale}
            warmup_steps: ${training.scheduler_warmup}
            cooldown_steps: ${training.scheduler_cooldown}
          param_names:
            - 'backbone.language_backbone.*'

      weight_decay:
        - scheduler:
            _target_: fvcore.common.param_scheduler.ConstantParamScheduler
            value: ${training.weight_decay}
        - scheduler:
            _target_: fvcore.common.param_scheduler.ConstantParamScheduler
            value: 0.0
          param_names:
            - '*bias*'
          module_cls_names: ['torch.nn.LayerNorm']

  # Checkpointing
  checkpoint:
    save_dir: ${launcher.experiment_log_dir}/checkpoints
    save_freq: ${training.checkpoint_freq}

  # Logging
  logging:
    tensorboard_writer:
      _target_: sam3.train.utils.logger.make_tensorboard_logger
      log_dir: ${launcher.experiment_log_dir}/tensorboard
      flush_secs: 120
      should_log: true
    wandb_writer: null
    log_dir: ${launcher.experiment_log_dir}/logs
    log_freq: 10

  # Evaluation metrics
  meters:
    val:
      detection:
        _target_: sam3.eval.coco_writer.PredictionDumper
        iou_type: "bbox"
        dump_dir: ${launcher.experiment_log_dir}/dumps
        merge_predictions: true
        postprocessor:
          _target_: sam3.eval.postprocessors.PostProcessImage
          max_dets_per_img: -1
          use_original_ids: true
          use_original_sizes_box: true
          use_presence: true
        gather_pred_via_filesys: false
        maxdets: 100
        pred_file_evaluators:
          - _target_: sam3.eval.coco_eval_offline.CocoEvaluatorOfflineWithPredFileEvaluators
            gt_path: ${training.ann_file_val}
            tide: false
            iou_type: "bbox"

# ============================================================================
# Launcher Configuration
# ============================================================================
launcher:
  num_nodes: 1
  gpus_per_node: 1                 # Adjust based on your GPU setup
  experiment_log_dir: ${paths.experiment_log_dir}
  multiprocessing_context: forkserver

submitit:
  use_cluster: false               # Set to true for SLURM cluster
  account: null
  partition: null
  qos: null
  timeout_hour: 72
  cpus_per_task: 10
  port_range: [10000, 65000]
